{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aminatkhamokova/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "#import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- ------------\n",
      "absl-py                            2.0.0\n",
      "aiobotocore                        2.7.0\n",
      "aiohttp                            3.9.0\n",
      "aioitertools                       0.7.1\n",
      "aiosignal                          1.2.0\n",
      "alabaster                          0.7.12\n",
      "anaconda-anon-usage                0.4.2\n",
      "anaconda-catalogs                  0.2.0\n",
      "anaconda-client                    1.12.1\n",
      "anaconda-cloud-auth                0.1.4\n",
      "anaconda-navigator                 2.5.0\n",
      "anaconda-project                   0.11.1\n",
      "anyio                              3.5.0\n",
      "appdirs                            1.4.4\n",
      "applaunchservices                  0.3.0\n",
      "appnope                            0.1.2\n",
      "appscript                          1.1.2\n",
      "archspec                           0.2.1\n",
      "argon2-cffi                        21.3.0\n",
      "argon2-cffi-bindings               21.2.0\n",
      "arrow                              1.2.3\n",
      "astroid                            2.14.2\n",
      "astropy                            5.3.4\n",
      "asttokens                          2.0.5\n",
      "astunparse                         1.6.3\n",
      "async-lru                          2.0.4\n",
      "atomicwrites                       1.4.0\n",
      "attrs                              23.1.0\n",
      "Automat                            20.2.0\n",
      "autopep8                           1.6.0\n",
      "azure-core                         1.30.0\n",
      "azure-identity                     1.15.0\n",
      "Babel                              2.11.0\n",
      "backports.functools-lru-cache      1.6.4\n",
      "backports.tempfile                 1.0\n",
      "backports.weakref                  1.0.post1\n",
      "bcrypt                             3.2.0\n",
      "beautifulsoup4                     4.12.2\n",
      "binaryornot                        0.4.4\n",
      "black                              23.11.0\n",
      "bleach                             4.1.0\n",
      "bokeh                              3.3.0\n",
      "boltons                            23.0.0\n",
      "botocore                           1.31.64\n",
      "Bottleneck                         1.3.5\n",
      "Brotli                             1.0.9\n",
      "cachetools                         5.3.2\n",
      "catboost                           1.2.2\n",
      "certifi                            2023.11.17\n",
      "cffi                               1.16.0\n",
      "cfgv                               3.4.0\n",
      "chardet                            4.0.0\n",
      "charset-normalizer                 2.0.4\n",
      "clarabel                           0.6.0\n",
      "click                              8.1.7\n",
      "cloudpickle                        2.2.1\n",
      "clyent                             1.2.2\n",
      "colorama                           0.4.6\n",
      "colorcet                           3.0.1\n",
      "comm                               0.1.2\n",
      "conda                              23.11.0\n",
      "conda-build                        3.28.3\n",
      "conda-content-trust                0.2.0\n",
      "conda_index                        0.3.0\n",
      "conda-libmamba-solver              23.12.0\n",
      "conda-pack                         0.6.0\n",
      "conda-package-handling             2.2.0\n",
      "conda_package_streaming            0.9.0\n",
      "conda-repo-cli                     1.0.75\n",
      "conda-token                        0.4.0\n",
      "conda-verify                       3.4.2\n",
      "constantly                         23.10.4\n",
      "contourpy                          1.2.0\n",
      "cookiecutter                       2.5.0\n",
      "cryptography                       41.0.7\n",
      "cssselect                          1.1.0\n",
      "cvxopt                             1.3.2\n",
      "cvxpy                              1.4.1\n",
      "cycler                             0.11.0\n",
      "cylp                               0.92.2\n",
      "Cython                             0.29.37\n",
      "cytoolz                            0.12.2\n",
      "dask                               2023.11.0\n",
      "dataclasses-json                   0.6.4\n",
      "datasets                           2.12.0\n",
      "datashader                         0.16.0\n",
      "debugpy                            1.6.7\n",
      "decorator                          5.1.1\n",
      "defusedxml                         0.7.1\n",
      "Deprecated                         1.2.14\n",
      "diff-match-patch                   20200713\n",
      "dill                               0.3.6\n",
      "dirtyjson                          1.0.8\n",
      "distlib                            0.3.8\n",
      "distributed                        2023.11.0\n",
      "distro                             1.8.0\n",
      "docstring-to-markdown              0.11\n",
      "docutils                           0.18.1\n",
      "ecos                               2.0.12\n",
      "editables                          0.5\n",
      "entrypoints                        0.4\n",
      "et-xmlfile                         1.1.0\n",
      "evaluate                           0.4.1\n",
      "executing                          0.8.3\n",
      "fastjsonschema                     2.16.2\n",
      "filelock                           3.13.1\n",
      "flake8                             6.0.0\n",
      "Flask                              2.2.5\n",
      "flatbuffers                        23.5.26\n",
      "fonttools                          4.25.0\n",
      "frozenlist                         1.4.0\n",
      "fsspec                             2023.10.0\n",
      "future                             0.18.3\n",
      "gast                               0.5.4\n",
      "gensim                             4.3.0\n",
      "gmpy2                              2.1.2\n",
      "google-auth                        2.26.2\n",
      "google-auth-oauthlib               1.2.0\n",
      "google-pasta                       0.2.0\n",
      "graphviz                           0.20.1\n",
      "greenlet                           3.0.1\n",
      "grpcio                             1.60.0\n",
      "h11                                0.14.0\n",
      "h5py                               3.9.0\n",
      "hatch                              1.9.3\n",
      "hatchling                          1.21.1\n",
      "HeapDict                           1.0.1\n",
      "holisticai                         0.7.3\n",
      "holoviews                          1.18.1\n",
      "httpcore                           1.0.2\n",
      "httplib2                           0.22.0\n",
      "httpx                              0.26.0\n",
      "huggingface-hub                    0.21.1\n",
      "hvplot                             0.9.1\n",
      "hyperlink                          21.0.0\n",
      "identify                           2.5.33\n",
      "idna                               3.4\n",
      "imagecodecs                        2023.1.23\n",
      "imageio                            2.31.4\n",
      "imagesize                          1.4.1\n",
      "imbalanced-learn                   0.11.0\n",
      "importlib-metadata                 7.0.1\n",
      "incremental                        21.3.0\n",
      "inflection                         0.5.1\n",
      "iniconfig                          1.1.1\n",
      "intake                             0.6.8\n",
      "intervaltree                       3.1.0\n",
      "ipykernel                          6.25.0\n",
      "ipython                            8.20.0\n",
      "ipython-genutils                   0.2.0\n",
      "ipywidgets                         8.0.4\n",
      "isort                              5.9.3\n",
      "itemadapter                        0.3.0\n",
      "itemloaders                        1.0.4\n",
      "itsdangerous                       2.0.1\n",
      "jaraco.classes                     3.2.1\n",
      "jedi                               0.18.1\n",
      "jellyfish                          1.0.1\n",
      "Jinja2                             3.1.2\n",
      "jiwer                              3.0.3\n",
      "jmespath                           1.0.1\n",
      "joblib                             1.2.0\n",
      "json5                              0.9.6\n",
      "jsonpatch                          1.32\n",
      "jsonpointer                        2.1\n",
      "jsonschema                         4.19.2\n",
      "jsonschema-specifications          2023.7.1\n",
      "jupyter                            1.0.0\n",
      "jupyter_client                     8.6.0\n",
      "jupyter-console                    6.6.3\n",
      "jupyter_core                       5.5.0\n",
      "jupyter-events                     0.8.0\n",
      "jupyter-lsp                        2.2.0\n",
      "jupyter_server                     2.10.0\n",
      "jupyter_server_terminals           0.4.4\n",
      "jupyterlab                         4.0.8\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab_server                  2.25.1\n",
      "jupyterlab-widgets                 3.0.9\n",
      "kaleido                            0.2.1\n",
      "keras                              2.15.0\n",
      "keyring                            23.13.1\n",
      "kiwisolver                         1.4.4\n",
      "lazy_loader                        0.3\n",
      "lazy-object-proxy                  1.6.0\n",
      "libarchive-c                       2.9\n",
      "libclang                           16.0.6\n",
      "libmambapy                         1.5.6\n",
      "lightgbm                           4.2.0\n",
      "linkify-it-py                      2.0.0\n",
      "llama-index-core                   0.10.13\n",
      "llama-index-embeddings-huggingface 0.1.4\n",
      "llama-index-embeddings-openai      0.1.6\n",
      "llama-index-graph-stores-nebula    0.1.2\n",
      "llama-index-llms-azure-openai      0.1.4\n",
      "llama-index-llms-openai            0.1.6\n",
      "llamaindex-py-client               0.1.13\n",
      "llvmlite                           0.41.0\n",
      "lmdb                               1.4.1\n",
      "locket                             1.0.0\n",
      "lxml                               4.9.3\n",
      "lz4                                4.3.2\n",
      "Markdown                           3.4.1\n",
      "markdown-it-py                     2.2.0\n",
      "MarkupSafe                         2.1.3\n",
      "marshmallow                        3.21.0\n",
      "matplotlib                         3.8.0\n",
      "matplotlib-inline                  0.1.6\n",
      "mccabe                             0.7.0\n",
      "mdit-py-plugins                    0.3.0\n",
      "mdurl                              0.1.0\n",
      "menuinst                           2.0.1\n",
      "mistune                            2.0.4\n",
      "ml-dtypes                          0.2.0\n",
      "more-itertools                     10.1.0\n",
      "mpmath                             1.3.0\n",
      "msal                               1.27.0\n",
      "msal-extensions                    1.1.0\n",
      "msgpack                            1.0.3\n",
      "multidict                          6.0.4\n",
      "multipledispatch                   0.6.0\n",
      "multiprocess                       0.70.14\n",
      "munkres                            1.1.4\n",
      "mypy-extensions                    1.0.0\n",
      "navigator-updater                  0.4.0\n",
      "nbclient                           0.8.0\n",
      "nbconvert                          7.10.0\n",
      "nbformat                           5.9.2\n",
      "nebula3-python                     3.5.0\n",
      "nest-asyncio                       1.6.0\n",
      "networkx                           3.1\n",
      "nltk                               3.8.1\n",
      "nodeenv                            1.8.0\n",
      "notebook                           7.0.6\n",
      "notebook_shim                      0.2.3\n",
      "npm                                0.1.1\n",
      "numba                              0.58.1\n",
      "numexpr                            2.8.7\n",
      "numpy                              1.26.3\n",
      "numpydoc                           1.5.0\n",
      "oauthlib                           3.2.2\n",
      "openai                             1.12.0\n",
      "openpyxl                           3.0.10\n",
      "opt-einsum                         3.3.0\n",
      "optional-django                    0.1.0\n",
      "osqp                               0.6.3\n",
      "overrides                          7.4.0\n",
      "packaging                          23.1\n",
      "pandas                             2.1.4\n",
      "pandocfilters                      1.5.0\n",
      "panel                              1.3.1\n",
      "param                              2.0.1\n",
      "parsel                             1.6.0\n",
      "parso                              0.8.3\n",
      "partd                              1.4.1\n",
      "pathlib                            1.0.1\n",
      "pathspec                           0.10.3\n",
      "patsy                              0.5.3\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             10.0.1\n",
      "pip                                24.0\n",
      "pkce                               1.0.3\n",
      "pkginfo                            1.9.6\n",
      "platformdirs                       3.10.0\n",
      "platformquantlib                   0.0.1\n",
      "plotly                             5.9.0\n",
      "pluggy                             1.0.0\n",
      "ply                                3.11\n",
      "portalocker                        2.8.2\n",
      "pre-commit                         3.6.0\n",
      "prometheus-client                  0.14.1\n",
      "prompt-toolkit                     3.0.43\n",
      "Protego                            0.1.16\n",
      "protobuf                           4.23.4\n",
      "psutil                             5.9.0\n",
      "ptyprocess                         0.7.0\n",
      "pure-eval                          0.2.2\n",
      "py-cpuinfo                         9.0.0\n",
      "pyarrow                            11.0.0\n",
      "pyasn1                             0.4.8\n",
      "pyasn1-modules                     0.2.8\n",
      "pybind11                           2.11.1\n",
      "pycodestyle                        2.10.0\n",
      "pycosat                            0.6.6\n",
      "pycparser                          2.21\n",
      "pyct                               0.5.0\n",
      "pycurl                             7.45.2\n",
      "pydantic                           1.10.12\n",
      "PyDispatcher                       2.0.5\n",
      "pydocstyle                         6.3.0\n",
      "pyerfa                             2.0.0\n",
      "pyflakes                           3.0.1\n",
      "Pygments                           2.15.1\n",
      "PyJWT                              2.4.0\n",
      "pylint                             2.16.2\n",
      "pylint-venv                        2.3.0\n",
      "pyls-spyder                        0.4.0\n",
      "pyobjc-core                        9.0\n",
      "pyobjc-framework-Cocoa             9.0\n",
      "pyobjc-framework-CoreServices      9.0\n",
      "pyobjc-framework-FSEvents          9.0\n",
      "pyodbc                             4.0.39\n",
      "pyOpenSSL                          23.2.0\n",
      "pyparsing                          3.0.9\n",
      "PyQt5                              5.15.10\n",
      "PyQt5-sip                          12.13.0\n",
      "PyQtWebEngine                      5.15.6\n",
      "PySocks                            1.7.1\n",
      "pytest                             7.4.0\n",
      "python-dateutil                    2.8.2\n",
      "python-dotenv                      0.21.0\n",
      "python-json-logger                 2.0.7\n",
      "python-lsp-black                   1.2.1\n",
      "python-lsp-jsonrpc                 1.0.0\n",
      "python-lsp-server                  1.7.2\n",
      "python-slugify                     5.0.2\n",
      "python-snappy                      0.6.1\n",
      "pytoolconfig                       1.2.6\n",
      "pytz                               2023.3.post1\n",
      "pyviz_comms                        3.0.0\n",
      "PyWavelets                         1.4.1\n",
      "PyYAML                             6.0.1\n",
      "pyzmq                              25.1.0\n",
      "QDarkStyle                         3.0.2\n",
      "qdldl                              0.1.7.post0\n",
      "qstylizer                          0.2.2\n",
      "QtAwesome                          1.2.2\n",
      "qtconsole                          5.4.2\n",
      "QtPy                               2.4.1\n",
      "queuelib                           1.6.2\n",
      "rapidfuzz                          3.6.1\n",
      "referencing                        0.30.2\n",
      "regex                              2023.10.3\n",
      "requests                           2.31.0\n",
      "requests-file                      1.5.1\n",
      "requests-oauthlib                  1.3.1\n",
      "requests-toolbelt                  1.0.0\n",
      "responses                          0.13.3\n",
      "result                             0.16.0\n",
      "rfc3339-validator                  0.1.4\n",
      "rfc3986-validator                  0.1.1\n",
      "rich                               13.3.5\n",
      "rope                               1.7.0\n",
      "rpds-py                            0.10.6\n",
      "rsa                                4.9\n",
      "Rtree                              1.0.1\n",
      "ruamel.yaml                        0.17.21\n",
      "ruamel-yaml-conda                  0.17.21\n",
      "s3fs                               2023.10.0\n",
      "sacremoses                         0.1.1\n",
      "safetensors                        0.4.2\n",
      "scikit-image                       0.20.0\n",
      "scikit-learn                       1.2.1\n",
      "scipy                              1.11.4\n",
      "Scrapy                             2.8.0\n",
      "scs                                3.2.4.post1\n",
      "seaborn                            0.12.2\n",
      "semver                             2.13.0\n",
      "Send2Trash                         1.8.2\n",
      "sentencepiece                      0.2.0\n",
      "service-identity                   18.1.0\n",
      "setuptools                         68.0.0\n",
      "shellingham                        1.5.4\n",
      "sip                                6.7.12\n",
      "six                                1.16.0\n",
      "smart-open                         5.2.1\n",
      "sniffio                            1.2.0\n",
      "snowballstemmer                    2.2.0\n",
      "sortedcontainers                   2.4.0\n",
      "soupsieve                          2.5\n",
      "Sphinx                             5.0.2\n",
      "sphinxcontrib-applehelp            1.0.2\n",
      "sphinxcontrib-devhelp              1.0.2\n",
      "sphinxcontrib-htmlhelp             2.0.0\n",
      "sphinxcontrib-jsmath               1.0.1\n",
      "sphinxcontrib-qthelp               1.0.3\n",
      "sphinxcontrib-serializinghtml      1.1.5\n",
      "spyder                             5.4.3\n",
      "spyder-kernels                     2.4.4\n",
      "SQLAlchemy                         2.0.21\n",
      "stack-data                         0.2.0\n",
      "statsmodels                        0.14.0\n",
      "sympy                              1.12\n",
      "tables                             3.8.0\n",
      "tabulate                           0.9.0\n",
      "tblib                              1.7.0\n",
      "tenacity                           8.2.2\n",
      "tensorboard                        2.15.1\n",
      "tensorboard-data-server            0.7.2\n",
      "tensorflow                         2.15.0\n",
      "tensorflow-estimator               2.15.0\n",
      "tensorflow-io-gcs-filesystem       0.34.0\n",
      "tensorflow-macos                   2.15.0\n",
      "termcolor                          2.4.0\n",
      "terminado                          0.17.1\n",
      "text-unidecode                     1.3\n",
      "textdistance                       4.2.1\n",
      "threadpoolctl                      2.2.0\n",
      "three-merge                        0.1.1\n",
      "tifffile                           2023.4.12\n",
      "tiktoken                           0.6.0\n",
      "tinycss2                           1.2.1\n",
      "tldextract                         3.2.0\n",
      "tokenizers                         0.15.2\n",
      "toml                               0.10.2\n",
      "tomli_w                            1.0.0\n",
      "tomlkit                            0.11.1\n",
      "toolz                              0.12.0\n",
      "torch                              2.1.2\n",
      "torchaudio                         2.1.2\n",
      "torchvision                        0.16.2\n",
      "tornado                            6.3.3\n",
      "tqdm                               4.66.2\n",
      "traitlets                          5.7.1\n",
      "transformers                       4.38.1\n",
      "trove-classifiers                  2024.1.31\n",
      "truststore                         0.8.0\n",
      "Twisted                            22.10.0\n",
      "typing_extensions                  4.7.1\n",
      "typing-inspect                     0.9.0\n",
      "tzdata                             2023.3\n",
      "uc-micro-py                        1.0.1\n",
      "ujson                              5.4.0\n",
      "Unidecode                          1.2.0\n",
      "urllib3                            1.26.18\n",
      "userpath                           1.9.1\n",
      "virtualenv                         20.25.0\n",
      "w3lib                              1.21.0\n",
      "watchdog                           2.1.6\n",
      "wcwidth                            0.2.5\n",
      "webencodings                       0.5.1\n",
      "websocket-client                   0.58.0\n",
      "Werkzeug                           2.2.3\n",
      "whatthepatch                       1.0.2\n",
      "wheel                              0.38.4\n",
      "widgetsnbextension                 4.0.5\n",
      "wrapt                              1.14.1\n",
      "wurlitzer                          3.0.2\n",
      "xarray                             2023.6.0\n",
      "xlwings                            0.29.1\n",
      "xxhash                             2.0.2\n",
      "xyzservices                        2022.9.0\n",
      "yapf                               0.31.0\n",
      "yarl                               1.9.3\n",
      "zict                               3.0.0\n",
      "zipp                               3.17.0\n",
      "zope.interface                     5.4.0\n",
      "zstandard                          0.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downgrade to python 3.11 to run this \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import catboost \n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary classification\n",
    "bc = pd.read_csv('dataset/adults_train.csv')\n",
    "X_bc = bc.iloc[:,:-1]\n",
    "y_bc = bc.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression\n",
    "reg = pd.read_csv('dataset/insurance_train.csv')\n",
    "X_reg = reg.iloc[:,:-1]\n",
    "y_reg = reg.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiclass classification\n",
    "mc = pd.read_csv('dataset/healthcare_train.csv')\n",
    "X_mc = mc.iloc[:,:-1]\n",
    "y_mc = mc.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering\n",
    "clust = pd.read_csv('dataset/customers.csv')\n",
    "X_clust = clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/xgboost-2_0_2-binary_classification.joblib']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize and train XGBoost for binary classification, sklearn wrapper and booster\n",
    "model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
    "model.fit(X_bc, y_bc)\n",
    "joblib.dump(model, 'models/xgboost-2_0_2_sklearn-binary_classification.joblib')\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',  \n",
    "    'eval_metric': 'logloss',        \n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'random_state': 42\n",
    "}\n",
    "dtrain = xgb.DMatrix(X_bc, label=y_bc)\n",
    "xgb_booster = xgb.train(xgb_params, dtrain)\n",
    "joblib.dump(xgb_booster, 'models/xgboost-2_0_2-binary_classification.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/xgboost-2_0_2-regression.joblib']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize and train XGBoost for regression, sklearn wrapper and booster\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "model.fit(X_reg, y_reg)\n",
    "joblib.dump(model, 'models/xgboost-2_0_2_sklearn-regression.joblib')\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',  \n",
    "    'eval_metric': 'rmse',             \n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "dtrain = xgb.DMatrix(X_reg, label=y_reg)\n",
    "xgb_booster = xgb.train(xgb_params, dtrain, 100)\n",
    "joblib.dump(xgb_booster, 'models/xgboost-2_0_2-regression.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/xgboost-2_0_2-multiclass_classification.joblib']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train XGBoost for multiclass classification, sklearn wrapper and booster\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(y_mc)), eval_metric='mlogloss')\n",
    "model.fit(X_mc, y_mc)\n",
    "joblib.dump(model, 'models/xgboost-2_0_2_sklearn-multiclass_classification.joblib')\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'multi:softmax',  \n",
    "    'num_class': len(set(y_mc)),                 \n",
    "    'eval_metric': 'merror',        \n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "dtrain = xgb.DMatrix(X_mc, label=y_mc)\n",
    "xgb_booster = xgb.train(xgb_params, dtrain, 100)\n",
    "joblib.dump(xgb_booster, 'models/xgboost-2_0_2-multiclass_classification.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 247, number of negative: 553\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 459\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.308750 -> initscore=-0.805970\n",
      "[LightGBM] [Info] Start training from score -0.805970\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[0.92591974 0.03893028 0.11264418 0.07985956 0.58855613 0.26527948\n",
      " 0.0135076  0.05822512 0.31406606 0.00483907 0.16582796 0.13547015\n",
      " 0.02839448 0.09187615 0.72278259 0.08912179 0.03888439 0.0609621\n",
      " 0.1795415  0.03605694 0.94903132 0.61870446 0.04519246 0.35785816\n",
      " 0.76753439 0.16278341 0.86096484 0.4574156  0.0707596  0.02870311\n",
      " 0.22530592 0.11698706 0.00783503 0.41100518 0.65582376 0.70330277\n",
      " 0.30147432 0.03467916 0.02126169 0.29188838 0.13361295 0.50720421\n",
      " 0.94453477 0.78185106 0.44139323 0.08051198 0.03125396 0.0349373\n",
      " 0.71265025 0.01788417 0.09753659 0.63526168 0.43100534 0.32115196\n",
      " 0.12945779 0.03877386 0.04908832 0.74444009 0.02030218 0.08989452\n",
      " 0.79336533 0.73942368 0.76109893 0.88663348 0.01819408 0.74232869\n",
      " 0.03063727 0.02082699 0.04282326 0.01008017 0.16485594 0.20086799\n",
      " 0.79124332 0.03227139 0.91609398 0.04842538 0.96949967 0.01111456\n",
      " 0.01768862 0.4380728  0.07141645 0.74517335 0.90674847 0.17340086\n",
      " 0.67332158 0.04965807 0.10808971 0.46422688 0.59868306 0.03156516\n",
      " 0.04893497 0.13058717 0.08734157 0.04631565 0.09101196 0.61708451\n",
      " 0.69776082 0.01613654 0.02326541 0.00942334 0.18863861 0.26659665\n",
      " 0.18882734 0.05601971 0.27500524 0.03658942 0.84362388 0.70847449\n",
      " 0.13776746 0.20120103 0.78178857 0.01647826 0.01661726 0.64943011\n",
      " 0.0196578  0.71004428 0.04636834 0.03195436 0.06717353 0.06475512\n",
      " 0.89133239 0.18658024 0.73806638 0.88384456 0.57873492 0.72285871\n",
      " 0.07907871 0.03962399 0.65023401 0.08066995 0.11170313 0.06613279\n",
      " 0.80173393 0.30918276 0.17510517 0.57114663 0.16951444 0.09718346\n",
      " 0.16721289 0.37416715 0.15843655 0.81025544 0.67404487 0.1747691\n",
      " 0.286019   0.72441694 0.09969581 0.89982334 0.02342196 0.26828463\n",
      " 0.01131586 0.74749021 0.58448982 0.15002445 0.44652815 0.01717637\n",
      " 0.63700999 0.07374136 0.71600965 0.01007713 0.03147861 0.1582958\n",
      " 0.1033119  0.23915682 0.65868851 0.22718207 0.89718853 0.1028367\n",
      " 0.03028935 0.28682499 0.66901818 0.80065318 0.10962226 0.86605947\n",
      " 0.85794066 0.01505772 0.11447093 0.06760715 0.08892969 0.10938803\n",
      " 0.24079024 0.1509205  0.20900483 0.60462978 0.02713354 0.12523794\n",
      " 0.30731743 0.0748426  0.17676464 0.16481693 0.88630843 0.07162977\n",
      " 0.35658764 0.87608604 0.80201305 0.46071721 0.52975657 0.03175823\n",
      " 0.16998533 0.01477565 0.09926048 0.46441923 0.11393802 0.0222398\n",
      " 0.248567   0.01557449 0.07356207 0.22168652 0.70167823 0.03353489\n",
      " 0.79930603 0.15594671 0.12794446 0.1135852  0.27415889 0.6035505\n",
      " 0.74143578 0.62333651 0.39546889 0.0437834  0.50289259 0.6097389\n",
      " 0.88723904 0.10744764 0.30516871 0.04788499 0.47110459 0.04653065\n",
      " 0.11768238 0.06072552 0.11349826 0.92731533 0.13981293 0.05425009\n",
      " 0.03458705 0.14850074 0.40541872 0.95049785 0.60378662 0.78187851\n",
      " 0.10914078 0.54935966 0.32269176 0.4507093  0.10417923 0.15250203\n",
      " 0.05727653 0.00819014 0.7817929  0.81752333 0.08184825 0.29783882\n",
      " 0.03272976 0.01918275 0.58628203 0.68167789 0.21274331 0.15311603\n",
      " 0.72423583 0.8254299  0.68760291 0.29967004 0.15106694 0.03601014\n",
      " 0.15432582 0.1193639  0.06803615 0.07967757 0.16324149 0.07282487\n",
      " 0.0166412  0.36391159 0.70152025 0.01208302 0.02943733 0.02102741\n",
      " 0.48473528 0.25281521 0.1438383  0.9333658  0.1522857  0.14839985\n",
      " 0.07846318 0.08340367 0.83898445 0.11584887 0.05926911 0.07469047\n",
      " 0.15726754 0.7823508  0.06091875 0.07818351 0.1286765  0.65971082\n",
      " 0.55176538 0.11513318 0.05785466 0.39427869 0.01625648 0.35565735\n",
      " 0.02880434 0.33412472 0.02252817 0.0751467  0.36713692 0.05564424\n",
      " 0.03554248 0.02833838 0.24369572 0.1927184  0.67989857 0.02807068\n",
      " 0.25318668 0.02300717 0.83383372 0.85336614 0.23552557 0.0382138\n",
      " 0.1737116  0.66401242 0.0732392  0.22622011 0.07678061 0.08004221\n",
      " 0.04183993 0.04671791 0.65701494 0.33750385 0.81185573 0.72748885\n",
      " 0.07329911 0.75637081 0.75160343 0.02578152 0.65410443 0.1244522\n",
      " 0.07375503 0.46235355 0.04023997 0.19102561 0.12809628 0.0317852\n",
      " 0.84520751 0.16193683 0.78714277 0.76414233 0.82603191 0.64737352\n",
      " 0.16006074 0.02838325 0.29812672 0.14422094 0.60973021 0.05442351\n",
      " 0.67681444 0.11148827 0.00921439 0.16797266 0.08263639 0.87150024\n",
      " 0.78216302 0.64894223 0.23637612 0.0618128  0.056964   0.03194525\n",
      " 0.06354369 0.14547641 0.06356477 0.71380642 0.02525986 0.67093123\n",
      " 0.90757745 0.44060819 0.03845947 0.03496536 0.04570729 0.09284254\n",
      " 0.18066082 0.16060989 0.16438828 0.51499434 0.2827597  0.82527377\n",
      " 0.00969421 0.90922612 0.21554332 0.18304251 0.21392562 0.12056638\n",
      " 0.23526911 0.11684481 0.0933591  0.045866   0.07817042 0.93034171\n",
      " 0.40597367 0.52630013 0.04304772 0.01910483 0.13639123 0.85816278\n",
      " 0.72748737 0.16970612 0.0144529  0.60051557 0.02390835 0.03197032\n",
      " 0.10922903 0.55981197 0.03023587 0.04271184 0.50440412 0.50711428\n",
      " 0.14903755 0.70807739 0.46806703 0.44845098 0.28475634 0.05930174\n",
      " 0.09377705 0.1202807  0.11450982 0.85435712 0.49152233 0.16976224\n",
      " 0.88286269 0.05934161 0.02131706 0.47490863 0.27904134 0.02046131\n",
      " 0.04956779 0.46156704 0.13550373 0.40687252 0.11867654 0.12157151\n",
      " 0.04453644 0.92689009 0.02002085 0.26883793 0.22181167 0.22432941\n",
      " 0.03518927 0.0541919  0.09265242 0.47398323 0.56506332 0.81972949\n",
      " 0.63961255 0.30949733 0.22615942 0.0326516  0.10924802 0.01081395\n",
      " 0.24952446 0.19188274 0.60307706 0.51467819 0.17513682 0.5411328\n",
      " 0.92195522 0.74213882 0.50202225 0.21293372 0.05115562 0.08841614\n",
      " 0.77163259 0.70119979 0.11841906 0.7913077  0.1141871  0.83310204\n",
      " 0.03853564 0.18429063 0.11214037 0.26417254 0.94638504 0.07265294\n",
      " 0.89837912 0.82544046 0.79079764 0.19718938 0.41433506 0.63843226\n",
      " 0.18935252 0.70756764 0.4794511  0.03341051 0.02234929 0.1741474\n",
      " 0.42981217 0.80701866 0.15900315 0.15870847 0.5699287  0.10860063\n",
      " 0.72156686 0.00670685 0.02211215 0.10401627 0.88097763 0.09604657\n",
      " 0.25383284 0.10464667 0.30505836 0.10756695 0.05938361 0.73409268\n",
      " 0.80961257 0.06194605 0.67220401 0.40536178 0.54271427 0.8022519\n",
      " 0.45856911 0.08001393 0.91378047 0.02426762 0.03100426 0.29039018\n",
      " 0.03182003 0.01217928 0.89765118 0.7468894  0.81627557 0.83700396\n",
      " 0.38579034 0.35071091 0.05572737 0.20005362 0.11548362 0.50161667\n",
      " 0.0207779  0.16694826 0.0163603  0.0774429  0.0411605  0.71232817\n",
      " 0.23120457 0.7615568  0.79956644 0.0358778  0.15548134 0.01404758\n",
      " 0.11116141 0.13900443 0.77296809 0.68510611 0.40402876 0.33489188\n",
      " 0.05617414 0.17838372 0.03438021 0.120674   0.24027655 0.81376152\n",
      " 0.13026396 0.82943994 0.1628019  0.94465246 0.94704977 0.10033909\n",
      " 0.01178626 0.13465723 0.61513359 0.84749913 0.09959591 0.85073965\n",
      " 0.11464764 0.045772   0.02202923 0.96070768 0.12429503 0.82890313\n",
      " 0.63159413 0.06101182 0.06777743 0.93863989 0.00951806 0.85579421\n",
      " 0.04961904 0.70959933 0.02492405 0.0155201  0.02260016 0.08875383\n",
      " 0.00972798 0.0291389  0.0377015  0.10129114 0.19622639 0.13317945\n",
      " 0.1972652  0.1640855  0.84204333 0.38880001 0.82264474 0.02361893\n",
      " 0.19021793 0.71766633 0.02429997 0.28620338 0.03249318 0.12965832\n",
      " 0.07116115 0.75286507 0.1699253  0.3851244  0.8586935  0.0322047\n",
      " 0.28585556 0.00969845 0.03196743 0.47325273 0.89279315 0.03911807\n",
      " 0.10197994 0.08212021 0.06426297 0.03372055 0.55943046 0.65887699\n",
      " 0.00653124 0.07799678 0.02908018 0.42643004 0.30292886 0.71341188\n",
      " 0.34514397 0.54902855 0.21996453 0.6432369  0.08703644 0.66355144\n",
      " 0.40241319 0.5733081  0.12035195 0.22884798 0.10757401 0.35781155\n",
      " 0.04883902 0.85534767 0.05827741 0.69492682 0.26679701 0.12306926\n",
      " 0.07456787 0.02975632 0.78392373 0.02291589 0.01990368 0.40496069\n",
      " 0.02242241 0.7201492  0.04373721 0.13177814 0.00832427 0.02411322\n",
      " 0.11680549 0.52424924 0.02479057 0.10927915 0.07552748 0.06866887\n",
      " 0.45763696 0.035572   0.25537909 0.54281136 0.83432164 0.12168713\n",
      " 0.20291865 0.78592151 0.07193156 0.06604749 0.02781629 0.7329535\n",
      " 0.39016318 0.10415532 0.02899567 0.14964654 0.28917903 0.05660154\n",
      " 0.68773256 0.04190782 0.60330253 0.02408363 0.03676768 0.6056787\n",
      " 0.57320341 0.01294737 0.10962914 0.01318592 0.78106403 0.17926449\n",
      " 0.08309033 0.81044206 0.06984777 0.17907473 0.62637595 0.05286515\n",
      " 0.18377399 0.04482221 0.00940825 0.08966594 0.07913313 0.60853436\n",
      " 0.07315579 0.07703629 0.36342692 0.68780893 0.82015814 0.03126845\n",
      " 0.23241993 0.76201165 0.05193504 0.19770175 0.07877171 0.02887548\n",
      " 0.87944006 0.57729172 0.2997312  0.27843028 0.12870659 0.31561582\n",
      " 0.04058224 0.1114906  0.0557859  0.09159481 0.33095572 0.79392977\n",
      " 0.24007153 0.01939309 0.80414047 0.21125631 0.0269636  0.04667472\n",
      " 0.83660288 0.83957225 0.03762918 0.00985235 0.01168958 0.26205291\n",
      " 0.04752232 0.15801417 0.38905991 0.92824702 0.12700662 0.38179386\n",
      " 0.04849838 0.10319912 0.45378034 0.10527813 0.41579689 0.14636139\n",
      " 0.2196372  0.76344565 0.03316567 0.15052749 0.67733447 0.0601179\n",
      " 0.27816085 0.12107452 0.08540677 0.14723193 0.13369649 0.02334402\n",
      " 0.0130679  0.06140873 0.20425166 0.02465341 0.25311997 0.01402243\n",
      " 0.34876435 0.17336236 0.15793908 0.17589257 0.12046786 0.77722405\n",
      " 0.11662217 0.07638961 0.74137441 0.02300287 0.77679054 0.3195224\n",
      " 0.03282016 0.01199986 0.02645197 0.31237364 0.03160003 0.06998692\n",
      " 0.91277495 0.10907531 0.03295793 0.49001339 0.86086506 0.87555351\n",
      " 0.08970356 0.19631167]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/lightgbm-4_2_0-binary_classification.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train LightGBM for binary classification, sklearn wrapper and booster\n",
    "model = lgb.LGBMClassifier(objective='binary',\n",
    "                         boosting_type='gbdt',\n",
    "                         num_leaves=31,\n",
    "                         learning_rate=0.05,\n",
    "                         feature_fraction=0.9)\n",
    "model.fit(X_bc, y_bc)\n",
    "joblib.dump(model, 'models/lightgbm-4_2_0_sklearn-binary_classification.joblib')\n",
    "\n",
    "train_data = lgb.Dataset(X_bc, label=y_bc)\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',  \n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'max_depth': -1\n",
    "}\n",
    "bst = lgb.train(lgb_params, train_data, 100)\n",
    "print(bst.predict(X_bc))\n",
    "joblib.dump(bst, 'models/lightgbm-4_2_0-binary_classification.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 315\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 13173.332294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/lightgbm-4_2_0-regression.joblib']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train LightGBM for regression, sklearn wrapper and booster\n",
    "model = lgb.LGBMRegressor(objective='regression',\n",
    "                        boosting_type='gbdt',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        feature_fraction=0.9)\n",
    "model.fit(X_reg, y_reg)\n",
    "joblib.dump(model, 'models/lightgbm-4_2_0_sklearn-regression.joblib')\n",
    "\n",
    "train_data = lgb.Dataset(X_reg, label=y_reg)\n",
    "lgb_params = {\n",
    "    'objective': 'regression',  \n",
    "    'metric': 'rmse',            \n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "bst = lgb.train(lgb_params, train_data, 100)\n",
    "joblib.dump(bst, 'models/lightgbm-4_2_0-regression.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 596\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.068932\n",
      "[LightGBM] [Info] Start training from score -1.114742\n",
      "[LightGBM] [Info] Start training from score -1.112838\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/lightgbm-4_2_0-multiclass_classification.joblib']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train LightGBM for multiclass classification, sklearn wrapper and booster\n",
    "model = lgb.LGBMClassifier(objective='multiclass',\n",
    "                         num_class=3,  # Number of classes in your dataset\n",
    "                         boosting_type='gbdt',\n",
    "                         num_leaves=31,\n",
    "                         learning_rate=0.05,\n",
    "                         feature_fraction=0.9)\n",
    "model.fit(X_mc, y_mc)\n",
    "joblib.dump(model, 'models/lightgbm-4_2_0_sklearn-multiclass_classification.joblib')\n",
    "\n",
    "train_data = lgb.Dataset(X_mc, label=y_mc)\n",
    "lgb_params = {\n",
    "    'objective': 'multiclass',  \n",
    "    'num_class': len(set(y_mc)),              \n",
    "    'metric': 'multi_logloss',   \n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "bst = lgb.train(lgb_params, train_data, 100)\n",
    "joblib.dump(bst, 'models/lightgbm-4_2_0-multiclass_classification.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/scikit-learn-1_3_2-binary_classification.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train sklearn for binary classification\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_bc, y_bc)\n",
    "joblib.dump(model, 'models/scikit-learn-1_3_2-binary_classification.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/scikit-learn-1_3_2-regression.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train sklearn for regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_reg, y_reg)\n",
    "joblib.dump(model, 'models/scikit-learn-1_3_2-regression.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/scikit-learn-1_3_2-multiclass_classification.joblib']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train sklearn for multiclass classification\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_mc, y_mc)\n",
    "joblib.dump(model, 'models/scikit-learn-1_3_2-multiclass_classification.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/scikit-learn-1_3_2-clustering.joblib']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train sklearn for clustering\n",
    "model = KMeans(n_clusters=5, random_state=42)\n",
    "model.fit(X_clust)\n",
    "joblib.dump(model, 'models/scikit-learn-1_3_2-clustering.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        1.0\n",
       "3        1.0\n",
       "4        0.0\n",
       "        ... \n",
       "38995    0.0\n",
       "38996    0.0\n",
       "38997    0.0\n",
       "38998    0.0\n",
       "38999    0.0\n",
       "Name: class, Length: 39000, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1219/1219 [==============================] - 0s 286us/step - loss: 2.1922 - accuracy: 0.7762\n",
      "Epoch 2/10\n",
      "1219/1219 [==============================] - 0s 279us/step - loss: 1.4163 - accuracy: 0.7993\n",
      "Epoch 3/10\n",
      "1219/1219 [==============================] - 0s 281us/step - loss: 1.6981 - accuracy: 0.8082\n",
      "Epoch 4/10\n",
      "1219/1219 [==============================] - 0s 278us/step - loss: 1.3253 - accuracy: 0.8091\n",
      "Epoch 5/10\n",
      "1219/1219 [==============================] - 0s 281us/step - loss: 1.3250 - accuracy: 0.8060\n",
      "Epoch 6/10\n",
      "1219/1219 [==============================] - 0s 291us/step - loss: 1.0642 - accuracy: 0.8093\n",
      "Epoch 7/10\n",
      "1219/1219 [==============================] - 0s 283us/step - loss: 1.2226 - accuracy: 0.8108\n",
      "Epoch 8/10\n",
      "1219/1219 [==============================] - 0s 281us/step - loss: 1.8657 - accuracy: 0.8092\n",
      "Epoch 9/10\n",
      "1219/1219 [==============================] - 0s 284us/step - loss: 1.1292 - accuracy: 0.8131\n",
      "Epoch 10/10\n",
      "1219/1219 [==============================] - 0s 282us/step - loss: 1.0281 - accuracy: 0.8123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aminatkhamokova/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train tensorflow model for binary classification\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_bc.shape[1], activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_bc, y_bc, epochs=10, batch_size=32)\n",
    "#joblib.dump(model, 'models/tensorflow-2_15_0-binary_classification.joblib')\n",
    "model.save('models/tensorflow-2_15_0-binary_classification.h5')\n",
    "model.save('models/tensorflow-2_15_0-binary_classification.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 394us/step - loss: 317197248.0000\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 354us/step - loss: 316819424.0000\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 336us/step - loss: 316419904.0000\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 331us/step - loss: 315993568.0000\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 314us/step - loss: 315530208.0000\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 287us/step - loss: 314998912.0000\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 306us/step - loss: 314416512.0000\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 294us/step - loss: 313744256.0000\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 305us/step - loss: 313003776.0000\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 278us/step - loss: 312177312.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aminatkhamokova/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train tensorflow model for regression\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_reg.shape[1], activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_reg, y_reg, epochs=10, batch_size=32)\n",
    "#joblib.dump(model, 'models/tensorflow-2_15_0-regression.joblib')\n",
    "model.save('models/tensorflow-2_15_0-regression.h5')\n",
    "model.save('models/tensorflow-2_15_0-regression.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 0s 355us/step - loss: 240.1648 - accuracy: 0.3300\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 0s 352us/step - loss: 46.2621 - accuracy: 0.3340\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 0s 346us/step - loss: 43.4339 - accuracy: 0.3350\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 0s 338us/step - loss: 52.1187 - accuracy: 0.3349\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 0s 336us/step - loss: 35.7486 - accuracy: 0.3392\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 0s 338us/step - loss: 45.2107 - accuracy: 0.3204\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 0s 322us/step - loss: 48.7509 - accuracy: 0.3326\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 0s 336us/step - loss: 46.7899 - accuracy: 0.3339\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 0s 334us/step - loss: 60.1546 - accuracy: 0.3296\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 0s 424us/step - loss: 47.5495 - accuracy: 0.3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aminatkhamokova/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train tensorflow model for multiclass classification \n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_mc.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # Number of classes is set to 3\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_mc, y_mc, epochs=10, batch_size=32)\n",
    "#joblib.dump(model, 'models/tensorflow-2_15_0-multiclass_classification.joblib')\n",
    "model.save('models/tensorflow-2_15_0-multiclass_classification.h5')\n",
    "model.save('models/tensorflow-2_15_0-multiclass_classification.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6680273\ttotal: 13.5ms\tremaining: 6.74s\n",
      "100:\tlearn: 0.1287385\ttotal: 942ms\tremaining: 3.72s\n",
      "200:\tlearn: 0.0516764\ttotal: 1.9s\tremaining: 2.83s\n",
      "300:\tlearn: 0.0282615\ttotal: 2.85s\tremaining: 1.88s\n",
      "400:\tlearn: 0.0186566\ttotal: 3.79s\tremaining: 936ms\n",
      "499:\tlearn: 0.0136905\ttotal: 4.73s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/catboost-1_2_2-binary_classification.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train catboost model for binary classification, sklearn and booster\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='Logloss')\n",
    "model.fit(X_bc, y_bc, early_stopping_rounds=50, verbose=100)\n",
    "joblib.dump(model, 'models/catboost-1_2_2_sklearn-binary_classification.joblib')\n",
    "\n",
    "train_pool = catboost.Pool(X_bc, label=y_bc)\n",
    "catboost_params = {\n",
    "    'iterations': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'Logloss',  \n",
    "    'verbose': 0\n",
    "}\n",
    "catboost_model = CatBoostClassifier(**catboost_params)\n",
    "catboost_model.fit(train_pool)\n",
    "joblib.dump(catboost_model, 'models/catboost-1_2_2-binary_classification.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 11593.9832656\ttotal: 3.8ms\tremaining: 1.9s\n",
      "100:\tlearn: 3574.9122511\ttotal: 145ms\tremaining: 574ms\n",
      "200:\tlearn: 2789.0024317\ttotal: 327ms\tremaining: 486ms\n",
      "300:\tlearn: 2323.7274404\ttotal: 528ms\tremaining: 349ms\n",
      "400:\tlearn: 1962.7708051\ttotal: 728ms\tremaining: 180ms\n",
      "499:\tlearn: 1700.3736051\ttotal: 920ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/catboost-1_2_2-regression.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train catboost model for regression, sklearn and booster\n",
    "model = CatBoostRegressor(iterations=500, depth=10, learning_rate=0.05, loss_function='RMSE')\n",
    "model.fit(X_reg, y_reg, early_stopping_rounds=50, verbose=100)\n",
    "joblib.dump(model, 'models/catboost-1_2_2_sklearn-regression.joblib')\n",
    "\n",
    "train_pool = catboost.Pool(X_reg, label=y_reg)\n",
    "catboost_params = {\n",
    "    'iterations': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',  \n",
    "    'verbose': 0\n",
    "}\n",
    "catboost_model = CatBoostRegressor(**catboost_params)\n",
    "catboost_model.fit(train_pool)\n",
    "joblib.dump(catboost_model, 'models/catboost-1_2_2-regression.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0947772\ttotal: 14.3ms\tremaining: 7.13s\n",
      "100:\tlearn: 0.8642666\ttotal: 779ms\tremaining: 3.08s\n",
      "200:\tlearn: 0.7124993\ttotal: 1.55s\tremaining: 2.3s\n",
      "300:\tlearn: 0.6120539\ttotal: 2.31s\tremaining: 1.53s\n",
      "400:\tlearn: 0.5325977\ttotal: 3.07s\tremaining: 759ms\n",
      "499:\tlearn: 0.4668946\ttotal: 3.83s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/catboost-1_2_2-multiclass_classification.joblib']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train catboost model for multiclass classification, sklearn and booster\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.05, loss_function='MultiClass')\n",
    "model.fit(X_mc, y_mc, early_stopping_rounds=50, verbose=100)\n",
    "joblib.dump(model, 'models/catboost-1_2_2_sklearn-multiclass_classification.joblib')\n",
    "\n",
    "train_pool = catboost.Pool(X_mc, label=y_mc)\n",
    "catboost_params = {\n",
    "    'iterations': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'MultiClass',  \n",
    "    'verbose': 0\n",
    "}\n",
    "catboost_model = CatBoostClassifier(**catboost_params)\n",
    "catboost_model.fit(train_pool)\n",
    "joblib.dump(catboost_model, 'models/catboost-1_2_2-multiclass_classification.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 10.1416\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train PyTorch model for binary classification\n",
    "X_train = torch.Tensor(X_bc.values)\n",
    "y_train = torch.Tensor(y_bc)\n",
    "# Define a simple logistic regression model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.view(-1, 1))\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "#torch.save(model.state_dict(), 'models/torch-2_3_0-binary_classification.joblib')\n",
    "torch.save(model,'models/torch-2_2_1-binary_classification.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"models/torch-2_2_1-binary_classification.pth\"\n",
    "model = torch.load(model_name)\n",
    "df_test = pd.read_csv(\"dataset/adults_test.csv\")\n",
    "tensor = torch.Tensor(df_test.drop(columns=[\"class\"]).values)\n",
    "output = model(tensor)\n",
    "predicted_classes = (output > 0.5).int()  # Use threshold 0.5 for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 317471936.0000\n",
      "Epoch [200/1000], Loss: 317450368.0000\n",
      "Epoch [300/1000], Loss: 317428832.0000\n",
      "Epoch [400/1000], Loss: 317407328.0000\n",
      "Epoch [500/1000], Loss: 317385728.0000\n",
      "Epoch [600/1000], Loss: 317364224.0000\n",
      "Epoch [700/1000], Loss: 317342688.0000\n",
      "Epoch [800/1000], Loss: 317321120.0000\n",
      "Epoch [900/1000], Loss: 317299616.0000\n",
      "Epoch [1000/1000], Loss: 317278048.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train PyTorch model for regression\n",
    "X_train = torch.FloatTensor(X_reg.values)\n",
    "y_train = torch.FloatTensor(y_reg)\n",
    "# Define a simple regression model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 1)\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.view(-1, 1))\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "#torch.save(model.state_dict(), 'models/torch-2_3_0-regression.joblib')\n",
    "torch.save(model,'models/torch-2_2_1-regression.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 2663953.2500\n",
      "Epoch [200/1000], Loss: 966165.8750\n",
      "Epoch [300/1000], Loss: 2535061.2500\n",
      "Epoch [400/1000], Loss: 4042209.0000\n",
      "Epoch [500/1000], Loss: 2311546.2500\n",
      "Epoch [600/1000], Loss: 853570.1875\n",
      "Epoch [700/1000], Loss: 2422496.7500\n",
      "Epoch [800/1000], Loss: 3576131.7500\n",
      "Epoch [900/1000], Loss: 1846691.8750\n",
      "Epoch [1000/1000], Loss: 642834.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train PyTorch model for multiclass classification\n",
    "X_train = torch.FloatTensor(X_mc.values)\n",
    "y_train = torch.LongTensor(y_mc)\n",
    "# Define a simple multiclass classification model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 3)  # 3 output neurons for three classes\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "#torch.save(model.state_dict(), 'models/torch-2_3_0-multiclass_classification.joblib')\n",
    "torch.save(model,'models/torch-2_2_1-multiclass_classification.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_bc = joblib.load('models/lightgbm-4_2_0-binary_classification.joblib')\n",
    "lightgbm_reg = joblib.load('models/lightgbm-4_2_0-regression.joblib')\n",
    "lightgbm_mc = joblib.load('models/lightgbm-4_2_0-multiclass_classification.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bc = joblib.load('models/xgboost-2_0_2-binary_classification.joblib')\n",
    "xgb_reg = joblib.load('models/xgboost-2_0_2-regression.joblib')\n",
    "xgb_mc = joblib.load('models/xgboost-2_0_2-multiclass_classification.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_bc = joblib.load('models/catboost-1_2_2-binary_classification.joblib')\n",
    "cat_reg = joblib.load('models/catboost-1_2_2-regression.joblib')\n",
    "cat_mc = joblib.load('models/catboost-1_2_2-multiclass_classification.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nclass XGBBoosterWrapper(BaseEstimator, ClassifierMixin):\\n    def __init__(self, booster=None):\\n        self.booster_params = booster.get_dump()[0]\\n        self.booster = booster\\n\\n    def fit(self, X, y):\\n        params = self.booster_params.copy() if self.booster_params is not None else {}\\n        self.booster = xgb.train(params, xgb.DMatrix(X, label=y))\\n        return self\\n\\n    def predict(self, X):\\n        check_is_fitted(self, 'booster')\\n        return self.booster.predict(xgb.DMatrix(X))\\n    \\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class LGBMBoosterWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, booster=None):\n",
    "        self.booster_params = booster.params\n",
    "        self.booster = booster\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.booster = lgb.train(self.booster_params, lgb.Dataset(X, label=y))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'booster')\n",
    "        preds = self.booster.predict(X)\n",
    "        pred_class = (preds > 0.5).astype(\"int\")\n",
    "        return pred_class\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        check_is_fitted(self, 'booster')\n",
    "        return self.booster.predict(X)\n",
    "\n",
    "class CatBoosterWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, booster=None):\n",
    "        self.booster_params = booster.get_params()\n",
    "        self.booster = booster\n",
    "        self.is_classifier = isinstance(booster, CatBoostClassifier)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.booster = CatBoostClassifier(**self.booster_params) if self.is_classifier else CatBoostRegressor(**self.booster_params)\n",
    "        self.booster.fit(catboost.Pool(X, label = y))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'booster')\n",
    "        return self.booster.predict(X)   \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        check_is_fitted(self, 'booster')\n",
    "        if self.is_classifier:\n",
    "            return self.booster.predict_proba(X)\n",
    "        else:\n",
    "            raise AttributeError(\"predict_proba is only available for classifiers.\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class XGBBoosterWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, booster=None):\n",
    "        self.booster_params = booster.get_dump()[0]\n",
    "        self.booster = booster\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        params = self.booster_params.copy() if self.booster_params is not None else {}\n",
    "        self.booster = xgb.train(params, xgb.DMatrix(X, label=y))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'booster')\n",
    "        return self.booster.predict(xgb.DMatrix(X))\n",
    "    \n",
    "\"\"\"    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbc = LGBMBoosterWrapper(lightgbm_bc)\n",
    "lreg = LGBMBoosterWrapper(lightgbm_reg)\n",
    "lmc = LGBMBoosterWrapper(lightgbm_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc = CatBoosterWrapper(cat_bc)\n",
    "creg = CatBoosterWrapper(cat_reg)\n",
    "cmc = CatBoosterWrapper(cat_mc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
