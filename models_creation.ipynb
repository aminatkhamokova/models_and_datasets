{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import lightgbm as lgb\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary classification\n",
    "bc_adults = pd.read_csv('binary classification/datasets/adults/adults_train.csv')\n",
    "X_bc_adults = bc_adults.iloc[:,:-1]\n",
    "y_bc_adults = bc_adults.iloc[:,-1]\n",
    "\n",
    "bc_german = pd.read_csv('binary classification/datasets/german credit/german_credit_train.csv')\n",
    "X_bc_german = bc_german.iloc[:,:-1]\n",
    "y_bc_german = bc_german.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression\n",
    "reg = pd.read_csv('regression/datasets/insurance/insurance_train.csv')\n",
    "X_reg = reg.iloc[:,:-1]\n",
    "y_reg = reg.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiclass classification\n",
    "mc = pd.read_csv('multiclass classification/datasets/healthcare/healthcare_train.csv')\n",
    "X_mc = mc.iloc[:,:-1]\n",
    "y_mc = mc.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering\n",
    "clust = pd.read_csv('clustering/datasets/customers/customers.csv')\n",
    "X_clust = clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- ------------------\n",
      "absl-py                                  2.1.0\n",
      "aiohttp                                  3.9.3\n",
      "aiosignal                                1.3.1\n",
      "annotated-types                          0.6.0\n",
      "anyio                                    4.2.0\n",
      "appdirs                                  1.4.4\n",
      "appnope                                  0.1.3\n",
      "asgiref                                  3.7.2\n",
      "asttokens                                2.4.1\n",
      "astunparse                               1.6.3\n",
      "attrs                                    23.2.0\n",
      "azure-core                               1.30.0\n",
      "azure-identity                           1.15.0\n",
      "backoff                                  2.2.1\n",
      "bcrypt                                   4.1.2\n",
      "beautifulsoup4                           4.12.3\n",
      "bert-score                               0.3.13\n",
      "bs4                                      0.0.2\n",
      "build                                    1.0.3\n",
      "cachetools                               5.3.3\n",
      "certifi                                  2024.2.2\n",
      "cffi                                     1.16.0\n",
      "charset-normalizer                       2.0.12\n",
      "chroma-hnswlib                           0.7.3\n",
      "chromadb                                 0.4.23\n",
      "clarabel                                 0.6.0\n",
      "click                                    8.1.7\n",
      "coloredlogs                              15.0.1\n",
      "comm                                     0.2.0\n",
      "contourpy                                1.2.0\n",
      "cryptography                             42.0.5\n",
      "cssselect                                1.2.0\n",
      "cvxopt                                   1.3.2\n",
      "cvxpy                                    1.4.1\n",
      "cycler                                   0.12.1\n",
      "cylp                                     0.92.2\n",
      "dataclasses-json                         0.6.4\n",
      "datasets                                 2.17.1\n",
      "debugpy                                  1.8.0\n",
      "decorator                                5.1.1\n",
      "Deprecated                               1.2.14\n",
      "dill                                     0.3.8\n",
      "dirtyjson                                1.0.8\n",
      "distlib                                  0.3.8\n",
      "distro                                   1.9.0\n",
      "dm-tree                                  0.1.8\n",
      "ecos                                     2.0.12\n",
      "editables                                0.5\n",
      "evaluate                                 0.4.1\n",
      "executing                                2.0.1\n",
      "fake-useragent                           1.4.0\n",
      "fastapi                                  0.110.0\n",
      "filelock                                 3.13.1\n",
      "flatbuffers                              23.5.26\n",
      "fonttools                                4.45.0\n",
      "frozenlist                               1.4.1\n",
      "fsspec                                   2023.10.0\n",
      "future                                   1.0.0\n",
      "gast                                     0.5.4\n",
      "google-auth                              2.28.1\n",
      "google-pasta                             0.2.0\n",
      "googleapis-common-protos                 1.62.0\n",
      "greenlet                                 3.0.3\n",
      "grpcio                                   1.62.0\n",
      "h11                                      0.14.0\n",
      "h5py                                     3.10.0\n",
      "hatch                                    1.9.3\n",
      "hatchling                                1.21.1\n",
      "holisticai                               0.7.2\n",
      "httpcore                                 1.0.2\n",
      "httplib2                                 0.22.0\n",
      "httptools                                0.6.1\n",
      "httpx                                    0.26.0\n",
      "huggingface-hub                          0.20.3\n",
      "humanfriendly                            10.0\n",
      "hyperlink                                21.0.0\n",
      "idna                                     3.6\n",
      "importlib-metadata                       6.11.0\n",
      "importlib_resources                      6.1.2\n",
      "install-torch                            1.0\n",
      "ipykernel                                6.26.0\n",
      "ipynb-py-convert                         0.4.6\n",
      "ipython                                  8.17.2\n",
      "jaraco.classes                           3.3.1\n",
      "jedi                                     0.19.1\n",
      "Jinja2                                   3.1.2\n",
      "jiwer                                    3.0.3\n",
      "joblib                                   1.3.2\n",
      "jupyter_client                           8.6.0\n",
      "jupyter_core                             5.5.0\n",
      "keras                                    3.0.5\n",
      "keyring                                  24.3.0\n",
      "kiwisolver                               1.4.5\n",
      "kubernetes                               29.0.0\n",
      "Levenshtein                              0.25.0\n",
      "libclang                                 16.0.6\n",
      "lightgbm                                 4.2.0\n",
      "llama-index                              0.10.13.post1\n",
      "llama-index-agent-openai                 0.1.5\n",
      "llama-index-cli                          0.1.5\n",
      "llama-index-core                         0.10.13\n",
      "llama-index-embeddings-huggingface       0.1.4\n",
      "llama-index-embeddings-openai            0.1.6\n",
      "llama-index-graph-stores-nebula          0.1.2\n",
      "llama-index-indices-managed-llama-cloud  0.1.3\n",
      "llama-index-legacy                       0.9.48\n",
      "llama-index-llms-azure-openai            0.1.4\n",
      "llama-index-llms-openai                  0.1.6\n",
      "llama-index-multi-modal-llms-openai      0.1.4\n",
      "llama-index-program-openai               0.1.4\n",
      "llama-index-question-gen-openai          0.1.3\n",
      "llama-index-readers-file                 0.1.6\n",
      "llama-index-readers-llama-parse          0.1.3\n",
      "llama-index-vector-stores-chroma         0.1.4\n",
      "llama-parse                              0.3.4\n",
      "llamaindex-py-client                     0.1.13\n",
      "lxml                                     5.0.0\n",
      "Markdown                                 3.5.2\n",
      "markdown-it-py                           3.0.0\n",
      "MarkupSafe                               2.1.3\n",
      "marshmallow                              3.21.0\n",
      "matplotlib                               3.8.2\n",
      "matplotlib-inline                        0.1.6\n",
      "mdurl                                    0.1.2\n",
      "ml-dtypes                                0.3.2\n",
      "mmh3                                     4.1.0\n",
      "monotonic                                1.6\n",
      "more-itertools                           10.2.0\n",
      "mpmath                                   1.2.1\n",
      "msal                                     1.27.0\n",
      "msal-extensions                          1.1.0\n",
      "multidict                                6.0.5\n",
      "multiprocess                             0.70.16\n",
      "mypy-extensions                          1.0.0\n",
      "namex                                    0.0.7\n",
      "nebula3-python                           3.5.0\n",
      "nest-asyncio                             1.5.8\n",
      "networkx                                 3.2.1\n",
      "nltk                                     3.8.1\n",
      "numpy                                    1.26.4\n",
      "oauthlib                                 3.2.2\n",
      "onnxruntime                              1.17.1\n",
      "openai                                   1.12.0\n",
      "opentelemetry-api                        1.23.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.23.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.23.0\n",
      "opentelemetry-instrumentation            0.44b0\n",
      "opentelemetry-instrumentation-asgi       0.44b0\n",
      "opentelemetry-instrumentation-fastapi    0.44b0\n",
      "opentelemetry-proto                      1.23.0\n",
      "opentelemetry-sdk                        1.23.0\n",
      "opentelemetry-semantic-conventions       0.44b0\n",
      "opentelemetry-util-http                  0.44b0\n",
      "opt-einsum                               3.3.0\n",
      "orjson                                   3.9.15\n",
      "osqp                                     0.6.3\n",
      "overrides                                7.7.0\n",
      "packaging                                23.2\n",
      "pandas                                   2.2.0\n",
      "parse                                    1.20.0\n",
      "parso                                    0.8.3\n",
      "pathspec                                 0.12.1\n",
      "pexpect                                  4.8.0\n",
      "Pillow                                   10.1.0\n",
      "pip                                      24.0\n",
      "platformdirs                             4.0.0\n",
      "platformquantlib                         0.0.1\n",
      "pluggy                                   1.4.0\n",
      "portalocker                              2.8.2\n",
      "posthog                                  3.4.2\n",
      "prompt-toolkit                           3.0.41\n",
      "protobuf                                 4.25.3\n",
      "psutil                                   5.9.6\n",
      "ptyprocess                               0.7.0\n",
      "pulsar-client                            3.4.0\n",
      "pure-eval                                0.2.2\n",
      "pyarrow                                  15.0.0\n",
      "pyarrow-hotfix                           0.6\n",
      "pyasn1                                   0.5.1\n",
      "pyasn1-modules                           0.3.0\n",
      "pybind11                                 2.11.1\n",
      "pycparser                                2.21\n",
      "pydantic                                 2.6.1\n",
      "pydantic_core                            2.16.2\n",
      "pyee                                     8.2.2\n",
      "Pygments                                 2.16.1\n",
      "PyJWT                                    2.8.0\n",
      "PyMuPDF                                  1.23.25\n",
      "PyMuPDFb                                 1.23.22\n",
      "pyparsing                                3.1.1\n",
      "pypdf                                    4.0.2\n",
      "PyPika                                   0.48.9\n",
      "pyppeteer                                1.0.2\n",
      "pyproject_hooks                          1.0.0\n",
      "pyquery                                  2.0.0\n",
      "python-dateutil                          2.8.2\n",
      "python-dotenv                            1.0.1\n",
      "python-Levenshtein                       0.25.0\n",
      "pytorch-nlp                              0.5.0\n",
      "pytz                                     2023.3.post1\n",
      "PyYAML                                   6.0.1\n",
      "pyzmq                                    25.1.1\n",
      "qdldl                                    0.1.7.post0\n",
      "rapidfuzz                                3.6.1\n",
      "regex                                    2023.12.25\n",
      "requests                                 2.31.0\n",
      "requests-html                            0.10.0\n",
      "requests-oauthlib                        1.3.1\n",
      "responses                                0.18.0\n",
      "result                                   0.16.0\n",
      "rich                                     13.7.0\n",
      "rouge_score                              0.1.2\n",
      "rsa                                      4.9\n",
      "sacremoses                               0.1.1\n",
      "safetensors                              0.4.2\n",
      "scikit-base                              0.6.1\n",
      "scikit-learn                             1.4.0\n",
      "scipy                                    1.11.3\n",
      "scs                                      3.2.4.post1\n",
      "seaborn                                  0.13.2\n",
      "sentencepiece                            0.2.0\n",
      "setuptools                               68.2.2\n",
      "shellingham                              1.5.4\n",
      "six                                      1.16.0\n",
      "sktime                                   0.24.1\n",
      "sniffio                                  1.3.0\n",
      "soupsieve                                2.5\n",
      "SQLAlchemy                               2.0.27\n",
      "stack-data                               0.6.3\n",
      "starlette                                0.36.3\n",
      "sympy                                    1.11.1\n",
      "tenacity                                 8.2.3\n",
      "tensorboard                              2.16.2\n",
      "tensorboard-data-server                  0.7.2\n",
      "tensorflow                               2.16.1\n",
      "termcolor                                2.4.0\n",
      "tf_keras                                 2.16.0\n",
      "threadpoolctl                            3.2.0\n",
      "tiktoken                                 0.6.0\n",
      "tokenizers                               0.15.2\n",
      "tomli_w                                  1.0.0\n",
      "tomlkit                                  0.12.3\n",
      "torch                                    2.2.1\n",
      "torchaudio                               2.2.0.dev20240104\n",
      "torchvision                              0.18.0.dev20240104\n",
      "tornado                                  6.3.3\n",
      "tqdm                                     4.66.1\n",
      "traitlets                                5.13.0\n",
      "transformers                             4.38.0\n",
      "trove-classifiers                        2024.1.31\n",
      "typer                                    0.9.0\n",
      "typing_extensions                        4.8.0\n",
      "typing-inspect                           0.9.0\n",
      "tzdata                                   2023.3\n",
      "urllib3                                  1.26.18\n",
      "userpath                                 1.9.1\n",
      "uvicorn                                  0.27.1\n",
      "uvloop                                   0.19.0\n",
      "virtualenv                               20.25.0\n",
      "w3lib                                    2.1.2\n",
      "watchfiles                               0.21.0\n",
      "wcwidth                                  0.2.10\n",
      "websocket-client                         1.7.0\n",
      "websockets                               10.4\n",
      "Werkzeug                                 3.0.1\n",
      "wget                                     3.2\n",
      "wheel                                    0.42.0\n",
      "wrapt                                    1.16.0\n",
      "xgboost                                  2.0.2\n",
      "xxhash                                   3.4.1\n",
      "yarl                                     1.9.4\n",
      "zipp                                     3.17.0\n",
      "zstandard                                0.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 9244, number of negative: 29756\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 367\n",
      "[LightGBM] [Info] Number of data points in the train set: 39000, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.237026 -> initscore=-1.169056\n",
      "[LightGBM] [Info] Start training from score -1.169056\n",
      "[0.02746073 0.28400039 0.14518856 ... 0.04014923 0.00438456 0.08562547]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['binary classification/models/lightgbm-4_2_0-binary_classification_adults.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train LightGBM for binary classification, sklearn wrapper and booster\n",
    "model = lgb.LGBMClassifier(objective='binary',\n",
    "                         boosting_type='gbdt',\n",
    "                         num_leaves=31,\n",
    "                         learning_rate=0.05,\n",
    "                         feature_fraction=0.9)\n",
    "model.fit(X_bc_adults, y_bc_adults)\n",
    "joblib.dump(model, 'binary classification/models/lightgbm-4_2_0_sklearn-binary_classification_adults.joblib')\n",
    "\n",
    "train_data = lgb.Dataset(X_bc_adults, label=y_bc_adults)\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',  \n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'max_depth': -1\n",
    "}\n",
    "bst = lgb.train(lgb_params, train_data, 100)\n",
    "print(bst.predict(X_bc_adults))\n",
    "joblib.dump(bst, 'binary classification/models/lightgbm-4_2_0-binary_classification_adults.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 247, number of negative: 553\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 459\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.308750 -> initscore=-0.805970\n",
      "[LightGBM] [Info] Start training from score -0.805970\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[0.92591974 0.03893028 0.11264418 0.07985956 0.58855613 0.26527948\n",
      " 0.0135076  0.05822512 0.31406606 0.00483907 0.16582796 0.13547015\n",
      " 0.02839448 0.09187615 0.72278259 0.08912179 0.03888439 0.0609621\n",
      " 0.1795415  0.03605694 0.94903132 0.61870446 0.04519246 0.35785816\n",
      " 0.76753439 0.16278341 0.86096484 0.4574156  0.0707596  0.02870311\n",
      " 0.22530592 0.11698706 0.00783503 0.41100518 0.65582376 0.70330277\n",
      " 0.30147432 0.03467916 0.02126169 0.29188838 0.13361295 0.50720421\n",
      " 0.94453477 0.78185106 0.44139323 0.08051198 0.03125396 0.0349373\n",
      " 0.71265025 0.01788417 0.09753659 0.63526168 0.43100534 0.32115196\n",
      " 0.12945779 0.03877386 0.04908832 0.74444009 0.02030218 0.08989452\n",
      " 0.79336533 0.73942368 0.76109893 0.88663348 0.01819408 0.74232869\n",
      " 0.03063727 0.02082699 0.04282326 0.01008017 0.16485594 0.20086799\n",
      " 0.79124332 0.03227139 0.91609398 0.04842538 0.96949967 0.01111456\n",
      " 0.01768862 0.4380728  0.07141645 0.74517335 0.90674847 0.17340086\n",
      " 0.67332158 0.04965807 0.10808971 0.46422688 0.59868306 0.03156516\n",
      " 0.04893497 0.13058717 0.08734157 0.04631565 0.09101196 0.61708451\n",
      " 0.69776082 0.01613654 0.02326541 0.00942334 0.18863861 0.26659665\n",
      " 0.18882734 0.05601971 0.27500524 0.03658942 0.84362388 0.70847449\n",
      " 0.13776746 0.20120103 0.78178857 0.01647826 0.01661726 0.64943011\n",
      " 0.0196578  0.71004428 0.04636834 0.03195436 0.06717353 0.06475512\n",
      " 0.89133239 0.18658024 0.73806638 0.88384456 0.57873492 0.72285871\n",
      " 0.07907871 0.03962399 0.65023401 0.08066995 0.11170313 0.06613279\n",
      " 0.80173393 0.30918276 0.17510517 0.57114663 0.16951444 0.09718346\n",
      " 0.16721289 0.37416715 0.15843655 0.81025544 0.67404487 0.1747691\n",
      " 0.286019   0.72441694 0.09969581 0.89982334 0.02342196 0.26828463\n",
      " 0.01131586 0.74749021 0.58448982 0.15002445 0.44652815 0.01717637\n",
      " 0.63700999 0.07374136 0.71600965 0.01007713 0.03147861 0.1582958\n",
      " 0.1033119  0.23915682 0.65868851 0.22718207 0.89718853 0.1028367\n",
      " 0.03028935 0.28682499 0.66901818 0.80065318 0.10962226 0.86605947\n",
      " 0.85794066 0.01505772 0.11447093 0.06760715 0.08892969 0.10938803\n",
      " 0.24079024 0.1509205  0.20900483 0.60462978 0.02713354 0.12523794\n",
      " 0.30731743 0.0748426  0.17676464 0.16481693 0.88630843 0.07162977\n",
      " 0.35658764 0.87608604 0.80201305 0.46071721 0.52975657 0.03175823\n",
      " 0.16998533 0.01477565 0.09926048 0.46441923 0.11393802 0.0222398\n",
      " 0.248567   0.01557449 0.07356207 0.22168652 0.70167823 0.03353489\n",
      " 0.79930603 0.15594671 0.12794446 0.1135852  0.27415889 0.6035505\n",
      " 0.74143578 0.62333651 0.39546889 0.0437834  0.50289259 0.6097389\n",
      " 0.88723904 0.10744764 0.30516871 0.04788499 0.47110459 0.04653065\n",
      " 0.11768238 0.06072552 0.11349826 0.92731533 0.13981293 0.05425009\n",
      " 0.03458705 0.14850074 0.40541872 0.95049785 0.60378662 0.78187851\n",
      " 0.10914078 0.54935966 0.32269176 0.4507093  0.10417923 0.15250203\n",
      " 0.05727653 0.00819014 0.7817929  0.81752333 0.08184825 0.29783882\n",
      " 0.03272976 0.01918275 0.58628203 0.68167789 0.21274331 0.15311603\n",
      " 0.72423583 0.8254299  0.68760291 0.29967004 0.15106694 0.03601014\n",
      " 0.15432582 0.1193639  0.06803615 0.07967757 0.16324149 0.07282487\n",
      " 0.0166412  0.36391159 0.70152025 0.01208302 0.02943733 0.02102741\n",
      " 0.48473528 0.25281521 0.1438383  0.9333658  0.1522857  0.14839985\n",
      " 0.07846318 0.08340367 0.83898445 0.11584887 0.05926911 0.07469047\n",
      " 0.15726754 0.7823508  0.06091875 0.07818351 0.1286765  0.65971082\n",
      " 0.55176538 0.11513318 0.05785466 0.39427869 0.01625648 0.35565735\n",
      " 0.02880434 0.33412472 0.02252817 0.0751467  0.36713692 0.05564424\n",
      " 0.03554248 0.02833838 0.24369572 0.1927184  0.67989857 0.02807068\n",
      " 0.25318668 0.02300717 0.83383372 0.85336614 0.23552557 0.0382138\n",
      " 0.1737116  0.66401242 0.0732392  0.22622011 0.07678061 0.08004221\n",
      " 0.04183993 0.04671791 0.65701494 0.33750385 0.81185573 0.72748885\n",
      " 0.07329911 0.75637081 0.75160343 0.02578152 0.65410443 0.1244522\n",
      " 0.07375503 0.46235355 0.04023997 0.19102561 0.12809628 0.0317852\n",
      " 0.84520751 0.16193683 0.78714277 0.76414233 0.82603191 0.64737352\n",
      " 0.16006074 0.02838325 0.29812672 0.14422094 0.60973021 0.05442351\n",
      " 0.67681444 0.11148827 0.00921439 0.16797266 0.08263639 0.87150024\n",
      " 0.78216302 0.64894223 0.23637612 0.0618128  0.056964   0.03194525\n",
      " 0.06354369 0.14547641 0.06356477 0.71380642 0.02525986 0.67093123\n",
      " 0.90757745 0.44060819 0.03845947 0.03496536 0.04570729 0.09284254\n",
      " 0.18066082 0.16060989 0.16438828 0.51499434 0.2827597  0.82527377\n",
      " 0.00969421 0.90922612 0.21554332 0.18304251 0.21392562 0.12056638\n",
      " 0.23526911 0.11684481 0.0933591  0.045866   0.07817042 0.93034171\n",
      " 0.40597367 0.52630013 0.04304772 0.01910483 0.13639123 0.85816278\n",
      " 0.72748737 0.16970612 0.0144529  0.60051557 0.02390835 0.03197032\n",
      " 0.10922903 0.55981197 0.03023587 0.04271184 0.50440412 0.50711428\n",
      " 0.14903755 0.70807739 0.46806703 0.44845098 0.28475634 0.05930174\n",
      " 0.09377705 0.1202807  0.11450982 0.85435712 0.49152233 0.16976224\n",
      " 0.88286269 0.05934161 0.02131706 0.47490863 0.27904134 0.02046131\n",
      " 0.04956779 0.46156704 0.13550373 0.40687252 0.11867654 0.12157151\n",
      " 0.04453644 0.92689009 0.02002085 0.26883793 0.22181167 0.22432941\n",
      " 0.03518927 0.0541919  0.09265242 0.47398323 0.56506332 0.81972949\n",
      " 0.63961255 0.30949733 0.22615942 0.0326516  0.10924802 0.01081395\n",
      " 0.24952446 0.19188274 0.60307706 0.51467819 0.17513682 0.5411328\n",
      " 0.92195522 0.74213882 0.50202225 0.21293372 0.05115562 0.08841614\n",
      " 0.77163259 0.70119979 0.11841906 0.7913077  0.1141871  0.83310204\n",
      " 0.03853564 0.18429063 0.11214037 0.26417254 0.94638504 0.07265294\n",
      " 0.89837912 0.82544046 0.79079764 0.19718938 0.41433506 0.63843226\n",
      " 0.18935252 0.70756764 0.4794511  0.03341051 0.02234929 0.1741474\n",
      " 0.42981217 0.80701866 0.15900315 0.15870847 0.5699287  0.10860063\n",
      " 0.72156686 0.00670685 0.02211215 0.10401627 0.88097763 0.09604657\n",
      " 0.25383284 0.10464667 0.30505836 0.10756695 0.05938361 0.73409268\n",
      " 0.80961257 0.06194605 0.67220401 0.40536178 0.54271427 0.8022519\n",
      " 0.45856911 0.08001393 0.91378047 0.02426762 0.03100426 0.29039018\n",
      " 0.03182003 0.01217928 0.89765118 0.7468894  0.81627557 0.83700396\n",
      " 0.38579034 0.35071091 0.05572737 0.20005362 0.11548362 0.50161667\n",
      " 0.0207779  0.16694826 0.0163603  0.0774429  0.0411605  0.71232817\n",
      " 0.23120457 0.7615568  0.79956644 0.0358778  0.15548134 0.01404758\n",
      " 0.11116141 0.13900443 0.77296809 0.68510611 0.40402876 0.33489188\n",
      " 0.05617414 0.17838372 0.03438021 0.120674   0.24027655 0.81376152\n",
      " 0.13026396 0.82943994 0.1628019  0.94465246 0.94704977 0.10033909\n",
      " 0.01178626 0.13465723 0.61513359 0.84749913 0.09959591 0.85073965\n",
      " 0.11464764 0.045772   0.02202923 0.96070768 0.12429503 0.82890313\n",
      " 0.63159413 0.06101182 0.06777743 0.93863989 0.00951806 0.85579421\n",
      " 0.04961904 0.70959933 0.02492405 0.0155201  0.02260016 0.08875383\n",
      " 0.00972798 0.0291389  0.0377015  0.10129114 0.19622639 0.13317945\n",
      " 0.1972652  0.1640855  0.84204333 0.38880001 0.82264474 0.02361893\n",
      " 0.19021793 0.71766633 0.02429997 0.28620338 0.03249318 0.12965832\n",
      " 0.07116115 0.75286507 0.1699253  0.3851244  0.8586935  0.0322047\n",
      " 0.28585556 0.00969845 0.03196743 0.47325273 0.89279315 0.03911807\n",
      " 0.10197994 0.08212021 0.06426297 0.03372055 0.55943046 0.65887699\n",
      " 0.00653124 0.07799678 0.02908018 0.42643004 0.30292886 0.71341188\n",
      " 0.34514397 0.54902855 0.21996453 0.6432369  0.08703644 0.66355144\n",
      " 0.40241319 0.5733081  0.12035195 0.22884798 0.10757401 0.35781155\n",
      " 0.04883902 0.85534767 0.05827741 0.69492682 0.26679701 0.12306926\n",
      " 0.07456787 0.02975632 0.78392373 0.02291589 0.01990368 0.40496069\n",
      " 0.02242241 0.7201492  0.04373721 0.13177814 0.00832427 0.02411322\n",
      " 0.11680549 0.52424924 0.02479057 0.10927915 0.07552748 0.06866887\n",
      " 0.45763696 0.035572   0.25537909 0.54281136 0.83432164 0.12168713\n",
      " 0.20291865 0.78592151 0.07193156 0.06604749 0.02781629 0.7329535\n",
      " 0.39016318 0.10415532 0.02899567 0.14964654 0.28917903 0.05660154\n",
      " 0.68773256 0.04190782 0.60330253 0.02408363 0.03676768 0.6056787\n",
      " 0.57320341 0.01294737 0.10962914 0.01318592 0.78106403 0.17926449\n",
      " 0.08309033 0.81044206 0.06984777 0.17907473 0.62637595 0.05286515\n",
      " 0.18377399 0.04482221 0.00940825 0.08966594 0.07913313 0.60853436\n",
      " 0.07315579 0.07703629 0.36342692 0.68780893 0.82015814 0.03126845\n",
      " 0.23241993 0.76201165 0.05193504 0.19770175 0.07877171 0.02887548\n",
      " 0.87944006 0.57729172 0.2997312  0.27843028 0.12870659 0.31561582\n",
      " 0.04058224 0.1114906  0.0557859  0.09159481 0.33095572 0.79392977\n",
      " 0.24007153 0.01939309 0.80414047 0.21125631 0.0269636  0.04667472\n",
      " 0.83660288 0.83957225 0.03762918 0.00985235 0.01168958 0.26205291\n",
      " 0.04752232 0.15801417 0.38905991 0.92824702 0.12700662 0.38179386\n",
      " 0.04849838 0.10319912 0.45378034 0.10527813 0.41579689 0.14636139\n",
      " 0.2196372  0.76344565 0.03316567 0.15052749 0.67733447 0.0601179\n",
      " 0.27816085 0.12107452 0.08540677 0.14723193 0.13369649 0.02334402\n",
      " 0.0130679  0.06140873 0.20425166 0.02465341 0.25311997 0.01402243\n",
      " 0.34876435 0.17336236 0.15793908 0.17589257 0.12046786 0.77722405\n",
      " 0.11662217 0.07638961 0.74137441 0.02300287 0.77679054 0.3195224\n",
      " 0.03282016 0.01199986 0.02645197 0.31237364 0.03160003 0.06998692\n",
      " 0.91277495 0.10907531 0.03295793 0.49001339 0.86086506 0.87555351\n",
      " 0.08970356 0.19631167]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['binary classification/models/lightgbm-4_2_0-binary_classification_german.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train LightGBM for binary classification, sklearn wrapper and booster\n",
    "model = lgb.LGBMClassifier(objective='binary',\n",
    "                         boosting_type='gbdt',\n",
    "                         num_leaves=31,\n",
    "                         learning_rate=0.05,\n",
    "                         feature_fraction=0.9)\n",
    "model.fit(X_bc_german, y_bc_german)\n",
    "joblib.dump(model, 'binary classification/models/lightgbm-4_2_0_sklearn-binary_classification_german.joblib')\n",
    "\n",
    "train_data = lgb.Dataset(X_bc_german, label=y_bc_german)\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',  \n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'max_depth': -1\n",
    "}\n",
    "bst = lgb.train(lgb_params, train_data, 100)\n",
    "print(bst.predict(X_bc_german))\n",
    "joblib.dump(bst, 'binary classification/models/lightgbm-4_2_0-binary_classification_german.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 315\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 13173.332294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['regression/models/lightgbm-4_2_0-regression_insurance.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train LightGBM for regression, sklearn wrapper and booster\n",
    "model = lgb.LGBMRegressor(objective='regression',\n",
    "                        boosting_type='gbdt',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        feature_fraction=0.9)\n",
    "model.fit(X_reg, y_reg)\n",
    "joblib.dump(model, 'regression/models/lightgbm-4_2_0_sklearn-regression_insurance.joblib')\n",
    "\n",
    "train_data = lgb.Dataset(X_reg, label=y_reg)\n",
    "lgb_params = {\n",
    "    'objective': 'regression',  \n",
    "    'metric': 'rmse',            \n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "bst = lgb.train(lgb_params, train_data, 100)\n",
    "joblib.dump(bst, 'regression/models/lightgbm-4_2_0-regression_insurance.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 596\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.068932\n",
      "[LightGBM] [Info] Start training from score -1.114742\n",
      "[LightGBM] [Info] Start training from score -1.112838\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['multiclass classification/models/lightgbm-4_2_0-multiclass_classification_healthcare.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train LightGBM for multiclass classification, sklearn wrapper and booster\n",
    "model = lgb.LGBMClassifier(objective='multiclass',\n",
    "                         num_class=3,  # Number of classes in your dataset\n",
    "                         boosting_type='gbdt',\n",
    "                         num_leaves=31,\n",
    "                         learning_rate=0.05,\n",
    "                         feature_fraction=0.9)\n",
    "model.fit(X_mc, y_mc)\n",
    "joblib.dump(model, 'multiclass classification/models/lightgbm-4_2_0_sklearn-multiclass_classification_healthcare.joblib')\n",
    "\n",
    "train_data = lgb.Dataset(X_mc, label=y_mc)\n",
    "lgb_params = {\n",
    "    'objective': 'multiclass',  \n",
    "    'num_class': len(set(y_mc)),              \n",
    "    'metric': 'multi_logloss',   \n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "bst = lgb.train(lgb_params, train_data, 100)\n",
    "joblib.dump(bst, 'multiclass classification/models/lightgbm-4_2_0-multiclass_classification_healthcare.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['binary classification/models/scikit-learn-1_3_2-binary_classification_adults.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train sklearn for binary classification\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_bc_adults, y_bc_adults)\n",
    "joblib.dump(model, 'binary classification/models/scikit-learn-1_3_2-binary_classification_adults.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['binary classification/models/scikit-learn-1_3_2-binary_classification_german.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train sklearn for binary classification\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_bc_german, y_bc_german)\n",
    "joblib.dump(model, 'binary classification/models/scikit-learn-1_3_2-binary_classification_german.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regression/models/scikit-learn-1_3_2-regression_insurance.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train sklearn for regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_reg, y_reg)\n",
    "joblib.dump(model, 'regression/models/scikit-learn-1_3_2-regression_insurance.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multiclass classification/models/scikit-learn-1_3_2-multiclass_classification_healthcare.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train sklearn for multiclass classification\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_mc, y_mc)\n",
    "joblib.dump(model, 'multiclass classification/models/scikit-learn-1_3_2-multiclass_classification_healthcare.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clustering/models/scikit-learn-1_3_2-clustering_customers.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train sklearn for clustering\n",
    "model = KMeans(n_clusters=5, random_state=42)\n",
    "model.fit(X_clust)\n",
    "joblib.dump(model, 'clustering/models/scikit-learn-1_3_2-clustering_customers.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train PyTorch model for binary classification\n",
    "X_train = torch.Tensor(X_bc_adults.values)\n",
    "y_train = torch.Tensor(y_bc_adults)\n",
    "# Define a simple logistic regression model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.view(-1, 1))\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "torch.save(model,'binary classification/models/torch-2_2_1-binary_classification_adults.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"binary classification/models/torch-2_2_1-binary_classification_adults.pth\"\n",
    "model = torch.load(model_name)\n",
    "df_test = pd.read_csv(\"binary classification/datasets/adults/adults_test.csv\")\n",
    "tensor = torch.Tensor(df_test.drop(columns=[\"class\"]).values)\n",
    "output = model(tensor)\n",
    "predicted_classes = (output > 0.5).int()  # Use threshold 0.5 for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 30.8750\n",
      "Epoch [200/1000], Loss: 30.8750\n",
      "Epoch [300/1000], Loss: 30.8750\n",
      "Epoch [400/1000], Loss: 30.8750\n",
      "Epoch [500/1000], Loss: 30.8750\n",
      "Epoch [600/1000], Loss: 30.8750\n",
      "Epoch [700/1000], Loss: 30.8750\n",
      "Epoch [800/1000], Loss: 30.8750\n",
      "Epoch [900/1000], Loss: 30.8750\n",
      "Epoch [1000/1000], Loss: 30.8750\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train PyTorch model for binary classification\n",
    "X_train = torch.Tensor(X_bc_german.values)\n",
    "y_train = torch.Tensor(y_bc_german)\n",
    "# Define a simple logistic regression model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.view(-1, 1))\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "torch.save(model,'binary classification/models/torch-2_2_1-binary_classification_german.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"binary classification/models/torch-2_2_1-binary_classification_german.pth\"\n",
    "model = torch.load(model_name)\n",
    "df_test = pd.read_csv(\"binary classification/datasets/german credit/german_credit_test.csv\")\n",
    "tensor = torch.Tensor(df_test.drop(columns=[\"default\"]).values)\n",
    "output = model(tensor)\n",
    "predicted_classes = (output > 0.5).int()  # Use threshold 0.5 for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 315870528.0000\n",
      "Epoch [200/10000], Loss: 313738144.0000\n",
      "Epoch [300/10000], Loss: 311623520.0000\n",
      "Epoch [400/10000], Loss: 309526304.0000\n",
      "Epoch [500/10000], Loss: 307446272.0000\n",
      "Epoch [600/10000], Loss: 305383168.0000\n",
      "Epoch [700/10000], Loss: 303336640.0000\n",
      "Epoch [800/10000], Loss: 301306592.0000\n",
      "Epoch [900/10000], Loss: 299292704.0000\n",
      "Epoch [1000/10000], Loss: 297294720.0000\n",
      "Epoch [1100/10000], Loss: 295312512.0000\n",
      "Epoch [1200/10000], Loss: 293345760.0000\n",
      "Epoch [1300/10000], Loss: 291394304.0000\n",
      "Epoch [1400/10000], Loss: 289457952.0000\n",
      "Epoch [1500/10000], Loss: 287536448.0000\n",
      "Epoch [1600/10000], Loss: 285629632.0000\n",
      "Epoch [1700/10000], Loss: 283737408.0000\n",
      "Epoch [1800/10000], Loss: 281859488.0000\n",
      "Epoch [1900/10000], Loss: 279995776.0000\n",
      "Epoch [2000/10000], Loss: 278146048.0000\n",
      "Epoch [2100/10000], Loss: 276310176.0000\n",
      "Epoch [2200/10000], Loss: 274488064.0000\n",
      "Epoch [2300/10000], Loss: 272679488.0000\n",
      "Epoch [2400/10000], Loss: 270884384.0000\n",
      "Epoch [2500/10000], Loss: 269102592.0000\n",
      "Epoch [2600/10000], Loss: 267333984.0000\n",
      "Epoch [2700/10000], Loss: 265578480.0000\n",
      "Epoch [2800/10000], Loss: 263835920.0000\n",
      "Epoch [2900/10000], Loss: 262106208.0000\n",
      "Epoch [3000/10000], Loss: 260389280.0000\n",
      "Epoch [3100/10000], Loss: 258685008.0000\n",
      "Epoch [3200/10000], Loss: 256993344.0000\n",
      "Epoch [3300/10000], Loss: 255314128.0000\n",
      "Epoch [3400/10000], Loss: 253647376.0000\n",
      "Epoch [3500/10000], Loss: 251992928.0000\n",
      "Epoch [3600/10000], Loss: 250350720.0000\n",
      "Epoch [3700/10000], Loss: 248720752.0000\n",
      "Epoch [3800/10000], Loss: 247102912.0000\n",
      "Epoch [3900/10000], Loss: 245497136.0000\n",
      "Epoch [4000/10000], Loss: 243903408.0000\n",
      "Epoch [4100/10000], Loss: 242321568.0000\n",
      "Epoch [4200/10000], Loss: 240751680.0000\n",
      "Epoch [4300/10000], Loss: 239193648.0000\n",
      "Epoch [4400/10000], Loss: 237647456.0000\n",
      "Epoch [4500/10000], Loss: 236112992.0000\n",
      "Epoch [4600/10000], Loss: 234590256.0000\n",
      "Epoch [4700/10000], Loss: 233079248.0000\n",
      "Epoch [4800/10000], Loss: 231579936.0000\n",
      "Epoch [4900/10000], Loss: 230092128.0000\n",
      "Epoch [5000/10000], Loss: 228616000.0000\n",
      "Epoch [5100/10000], Loss: 227151376.0000\n",
      "Epoch [5200/10000], Loss: 225698320.0000\n",
      "Epoch [5300/10000], Loss: 224256736.0000\n",
      "Epoch [5400/10000], Loss: 222826640.0000\n",
      "Epoch [5500/10000], Loss: 221408016.0000\n",
      "Epoch [5600/10000], Loss: 220000768.0000\n",
      "Epoch [5700/10000], Loss: 218604960.0000\n",
      "Epoch [5800/10000], Loss: 217220512.0000\n",
      "Epoch [5900/10000], Loss: 215847424.0000\n",
      "Epoch [6000/10000], Loss: 214485664.0000\n",
      "Epoch [6100/10000], Loss: 213135280.0000\n",
      "Epoch [6200/10000], Loss: 211796128.0000\n",
      "Epoch [6300/10000], Loss: 210468336.0000\n",
      "Epoch [6400/10000], Loss: 209151760.0000\n",
      "Epoch [6500/10000], Loss: 207846480.0000\n",
      "Epoch [6600/10000], Loss: 206552384.0000\n",
      "Epoch [6700/10000], Loss: 205269568.0000\n",
      "Epoch [6800/10000], Loss: 203997936.0000\n",
      "Epoch [6900/10000], Loss: 202737472.0000\n",
      "Epoch [7000/10000], Loss: 201488256.0000\n",
      "Epoch [7100/10000], Loss: 200250208.0000\n",
      "Epoch [7200/10000], Loss: 199023248.0000\n",
      "Epoch [7300/10000], Loss: 197807424.0000\n",
      "Epoch [7400/10000], Loss: 196602688.0000\n",
      "Epoch [7500/10000], Loss: 195409088.0000\n",
      "Epoch [7600/10000], Loss: 194226672.0000\n",
      "Epoch [7700/10000], Loss: 193055328.0000\n",
      "Epoch [7800/10000], Loss: 191895040.0000\n",
      "Epoch [7900/10000], Loss: 190745792.0000\n",
      "Epoch [8000/10000], Loss: 189607584.0000\n",
      "Epoch [8100/10000], Loss: 188480432.0000\n",
      "Epoch [8200/10000], Loss: 187364288.0000\n",
      "Epoch [8300/10000], Loss: 186259152.0000\n",
      "Epoch [8400/10000], Loss: 185165040.0000\n",
      "Epoch [8500/10000], Loss: 184081936.0000\n",
      "Epoch [8600/10000], Loss: 183009808.0000\n",
      "Epoch [8700/10000], Loss: 181948640.0000\n",
      "Epoch [8800/10000], Loss: 180898448.0000\n",
      "Epoch [8900/10000], Loss: 179859152.0000\n",
      "Epoch [9000/10000], Loss: 178830784.0000\n",
      "Epoch [9100/10000], Loss: 177813344.0000\n",
      "Epoch [9200/10000], Loss: 176806784.0000\n",
      "Epoch [9300/10000], Loss: 175811136.0000\n",
      "Epoch [9400/10000], Loss: 174826400.0000\n",
      "Epoch [9500/10000], Loss: 173852512.0000\n",
      "Epoch [9600/10000], Loss: 172889456.0000\n",
      "Epoch [9700/10000], Loss: 171937232.0000\n",
      "Epoch [9800/10000], Loss: 170995824.0000\n",
      "Epoch [9900/10000], Loss: 170065248.0000\n",
      "Epoch [10000/10000], Loss: 169145440.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train PyTorch model for regression\n",
    "X_train = torch.FloatTensor(X_reg.values)\n",
    "y_train = torch.FloatTensor(y_reg)\n",
    "# Define a simple regression model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 1)\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.view(-1, 1))\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "#torch.save(model.state_dict(), 'models/torch-2_3_0-regression.joblib')\n",
    "torch.save(model,'regression/models/torch-2_2_1-regression_insurance.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 2665888.5000\n",
      "Epoch [200/1000], Loss: 961548.4375\n",
      "Epoch [300/1000], Loss: 2530439.5000\n",
      "Epoch [400/1000], Loss: 4044299.5000\n",
      "Epoch [500/1000], Loss: 2313611.0000\n",
      "Epoch [600/1000], Loss: 852011.0625\n",
      "Epoch [700/1000], Loss: 2421012.2500\n",
      "Epoch [800/1000], Loss: 3546060.2500\n",
      "Epoch [900/1000], Loss: 1815501.8750\n",
      "Epoch [1000/1000], Loss: 663847.3125\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train PyTorch model for multiclass classification\n",
    "X_train = torch.FloatTensor(X_mc.values)\n",
    "y_train = torch.LongTensor(y_mc)\n",
    "# Define a simple multiclass classification model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 3)  # 3 output neurons for three classes\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "#torch.save(model.state_dict(), 'models/torch-2_3_0-multiclass_classification.joblib')\n",
    "torch.save(model,'multiclass classification/models/torch-2_2_1-multiclass_classification_healthcare.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
